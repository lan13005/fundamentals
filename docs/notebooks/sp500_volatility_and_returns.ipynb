{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "The notebook studies the volatility and returns of the S&P 500 index\n",
    "\n",
    "Assumptions:\n",
    "- Using historical market cap data from macrotrends\n",
    "- Calculate returns based on historical close prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Use Case                           | Use Log Return Volatility    | Use Arithmetic Volatility |\n",
    "| ---------------------------------- | ---------------------------- | ------------------------- |\n",
    "| Theoretical models (e.g., GBM)     | ✅                            | ❌                         |\n",
    "| Sharpe ratio, risk-adjusted return | ❌                            | ✅                         |\n",
    "| Empirical finance, EDA             | ✅                            | ✅                         |\n",
    "| Long horizon compounding           | ✅                            | ❌                         |\n",
    "| Portfolio optimization             | Mixed (depends on framework) | ✅                         |\n",
    "\n",
    "- Arithmetic returns is more intuitive and is used in Sharpe ratio calculations\n",
    "- Log-returns are more convenient for theoretical models (e.g., Geometric Brownian Motion for compounding drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equations:\n",
    "- Arithmetic Return (Simple or Percentage Return)\n",
    "   - $r_t^{\\text{arith}} = \\frac{P_t - P_{t-1}}{P_{t-1}} = \\frac{P_t}{P_{t-1}} - 1$\n",
    "\n",
    "- Log Return (Continuously Compounded Return)\n",
    "   - $r_t^{\\text{log}} = \\ln\\left( \\frac{P_t}{P_{t-1}} \\right)$\n",
    "\n",
    "- Relationship Between Log and Arithmetic Returns\n",
    "  - $r_t^{\\text{arith}} = e^{r_t^{\\text{log}}} - 1$\n",
    "  - $r_t^{\\text{log}} = \\ln(1 + r_t^{\\text{arith}})$\n",
    "\n",
    "- Taylor Expansion of Log Return (Around 0)\n",
    "  - $ \\ln(1 + r) = r - \\frac{r^2}{2} + \\frac{r^3}{3} - \\frac{r^4}{4} + \\cdots $\n",
    "  - $\\Rightarrow r_t^{\\text{log}} \\approx r_t^{\\text{arith}} - \\frac{1}{2} \\left( r_t^{\\text{arith}} \\right)^2$\n",
    "  - Note: if small changes then log return is close to arithmetic return\n",
    "\n",
    "- Cumulative Return (Arithmetic)\n",
    "  - $R_{0 \\to T}^{\\text{arith}} = \\prod_{t=1}^T (1 + r_t^{\\text{arith}}) - 1$\n",
    "\n",
    "- Cumulative Return (Log)\n",
    "  - $R_{0 \\to T}^{\\text{log}} = \\sum_{t=1}^T r_t^{\\text{log}} = \\ln\\left( \\frac{P_T}{P_0} \\right)$\n",
    "\n",
    "- Annualization of Mean and Volatility\n",
    "  - Multiplying mean by $N$ and volatility by $\\sqrt{N}$ is **exact property of expectations under iid constant mean processes**\n",
    "  - Assuming $N$ trading periods per year (e.g., 252 for daily returns):\n",
    "  - Annualized Mean Return (Log):\n",
    "    - $\\mu_{\\text{annual}}^{\\text{log}} = N \\cdot \\bar{r}_{\\text{log}}$\n",
    "  - Annualized Mean Return (Arithmetic):\n",
    "    - $\\mu_{\\text{annual}}^{\\text{arith}} = N \\cdot \\bar{r}_{\\text{arith}}$\n",
    "  - Annualized Volatility (Both Types):\n",
    "    - $\\sigma_{\\text{annual}} = \\sqrt{N} \\cdot \\sigma_{\\text{daily}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model                              | Purpose / Description                                                                                                                                                                                                                   | When to Use                                                                                                                                                                                    | Pros                                                                                                                                                                                  | Cons                                                                                                                                                                                     |\n",
    "|------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Discounted Cash Flow (DCF)**     | Projects a company’s future free cash flows (FCF) to equity or to the firm and discounts them to present value using a chosen discount rate (typically WACC or cost of equity).                                                          | When you have reliable forecasts for revenue growth, margins, capex, and working capital; especially for established companies with reasonably predictable cash flows.                         | • Directly ties valuation to underlying cash-flow drivers<br>• Flexible: can model changing revenue, margins, capex, working capital, etc.<br>• Widely accepted as an “intrinsic” approach | • Highly sensitive to assumptions (growth rates, margins, discount rate)<br>• Terminal value often dominates—small tweaks in terminal inputs swing valuation<br>• Data-intensive        |\n",
    "| **Dividend Discount Model (DDM)** / **Gordon Growth** | Values a stock as the present value of expected future dividends. <br>• Constant-growth form: $P_0 = \\dfrac{D_1}{r - g}$ assumes dividends grow at a fixed rate $g$ forever.                                                                      | When the firm has a stable dividend policy and predictable payout ratio (e.g., utility companies, large blue-chips).                                                                            | • Very simple in constant-growth case (single formula)<br>• Directly captures yield + growth trade-off<br>• Ideal for mature, stable dividend payers                                   | • Only works for firms with predictable dividends (not for non-dividend payers)<br>• Assumes perpetual, constant growth ($g < r$)—hard to justify for high-growth or cyclical stocks |\n",
    "| **Relative Valuation (Multiples)** | Values a stock by comparing its valuation multiples (P/E, EV/EBITDA, P/B, etc.) to a set of comparable peers. <br>Example: If Company A trades at 15× EV/EBITDA and Company B (similar profile) trades at 10×, B may be “cheap.”         | When you need a quick “sanity check” or peer comparison; suitable for sectors with homogeneous business models (e.g., retail, manufacturing) and readily available multiples.                | • Quick to implement—only needs market prices and basic financial metrics<br>• Reflects current market sentiment (peer pricing)<br>• Common sanity check alongside DCF/DDM               | • Requires a truly comparable peer group—difficult if no close peers exist<br>• Ignores company-specific fundamentals unless adjusted<br>• Market multiples can be temporarily distorted   |\n",
    "| **Residual Income (RI) / EVA**     | Values equity as $P_0 = B_0 + \\sum_{t=1}^{\\infty} \\dfrac{(ROE_t - r_e)\\,B_{t-1}}{(1 + r_e)^t}$, where $B_t$ is book value at time $t$ and $r_e$ is cost of equity. Focuses on “excess” accounting profits above required return. | When dividends or FCF are erratic but accounting profits (ROE) are steady; useful for banks or insurance companies where book value and ROE are more stable metrics than cash flows.         | • Captures value created above cost of equity—suitable when FCF or dividends are erratic<br>• Connects accounting (book) to market value                                                 | • Requires reliable forecasts of future ROE and book value—often uncertain<br>• Sensitive to the choice of cost of equity $r_e$<br>• Less intuitive if reinvestment returns vary         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "from fundamentals.utility.general import update_plot_style\n",
    "\n",
    "update_plot_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = pd.read_parquet(\"../../macro_data/SP500_2025-03-31.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macrotrends = {}\n",
    "for ticker in sp500.ticker.values:\n",
    "    macrotrends[ticker] = pd.read_parquet(f\"../../macro_data/parquet/{ticker}_2025-03-31.parquet\")\n",
    "    if len(macrotrends[ticker]) == 0:\n",
    "        print(f\"Warning: {ticker} has no macrotrends data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = next(iter(macrotrends.values())).index[-5]\n",
    "end_date   = next(iter(macrotrends.values())).index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (end_date - start_date).days == 365 # ensure 1 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = \" \".join(sp500.ticker.values)\n",
    "\n",
    "# Use open price for the price\n",
    "data = yf.download(tickers, start=start_date, end=end_date, interval='1d', group_by='ticker', auto_adjust=True)\n",
    "open_data = data.xs('Open', axis=1, level='Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_caps = {'ticker': [], 'marketCap': []}\n",
    "for ticker, df in macrotrends.items():\n",
    "    market_caps['ticker'].append(ticker)\n",
    "    length_df = len(df['Market-Cap'])\n",
    "    market_cap = df['Market-Cap'].iloc[max(-1, length_df-5)]\n",
    "    market_caps['marketCap'].append(market_cap)\n",
    "market_caps = pd.DataFrame(market_caps)\n",
    "\n",
    "market_caps.index = market_caps.ticker\n",
    "market_caps.drop(columns=['ticker'], inplace=True)\n",
    "market_caps = market_caps.reindex(open_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = \" \".join(sp500.ticker.values)\n",
    "\n",
    "# Use open price for the price\n",
    "data = yf.download(tickers, start=start_date, end=end_date, interval='1d', group_by='ticker', auto_adjust=True)\n",
    "open_data = data.xs('Open', axis=1, level='Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Compute daily log and arithmetic returns\n",
    "logret = np.log(open_data / open_data.shift(1)).dropna()\n",
    "arithret = open_data.pct_change().dropna()\n",
    "trading_days = 252\n",
    "\n",
    "# 2. Annualized volatility and mean\n",
    "ann_vol_log = logret.std(axis=0) * np.sqrt(trading_days)\n",
    "ann_vol_arith = arithret.std(axis=0) * np.sqrt(trading_days)\n",
    "ann_mean_log = logret.mean(axis=0) * trading_days\n",
    "ann_mean_arith = arithret.mean(axis=0) * trading_days\n",
    "ann_ret_from_log = np.exp(ann_mean_log) - 1\n",
    "\n",
    "# 3. Annualized volatility (cross-section)\n",
    "#    vol_i = std(logret_i) * sqrt(trading_days)\n",
    "ann_vol = logret.std(axis=0) * np.sqrt(trading_days)\n",
    "\n",
    "# 4. Index weights (as of start date)\n",
    "weights = market_caps['marketCap'].values / market_caps['marketCap'].sum()\n",
    "\n",
    "# 5. Total returns over the year per ticker\n",
    "tot_ret = (open_data.iloc[-1] / open_data.iloc[0] - 1)\n",
    "\n",
    "assert np.isclose(sum(weights), 1)\n",
    "assert sum(market_caps.index == tot_ret.index) == len(market_caps)\n",
    "\n",
    "# 6. Contribution to index return\n",
    "contrib = weights * tot_ret\n",
    "contrib_sorted = contrib.sort_values(ascending=False)\n",
    "contrib_sorted = contrib_sorted.reset_index()\n",
    "contrib_sorted.columns = ['ticker', 'contribution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(15,12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "iax = 0\n",
    "all_logret = logret.values.flatten()\n",
    "axes[iax].hist(all_logret, bins=50)\n",
    "axes[iax].axvline(np.median(all_logret), color='tab:orange', linewidth=2, linestyle='--', label=f'Median: {np.median(all_logret):.2f}')\n",
    "axes[iax].set_xlabel(\"Aggregated Daily Log Returns\")\n",
    "axes[iax].set_ylabel(\"Counts\")\n",
    "axes[iax].legend()\n",
    "\n",
    "iax = 1\n",
    "all_arithret = arithret.values.flatten()\n",
    "axes[iax].hist(all_arithret, bins=50)\n",
    "axes[iax].axvline(np.median(all_arithret), color='tab:orange', linewidth=2, linestyle='--', label=f'Median: {np.median(all_arithret):.2f}')\n",
    "axes[iax].set_xlabel(\"Aggregated Daily Arithmetic Returns\")\n",
    "axes[iax].set_ylabel(\"Counts\")\n",
    "axes[iax].legend()\n",
    "\n",
    "iax = 2\n",
    "axes[iax].hist(ann_vol_log, bins=50)\n",
    "axes[iax].axvline(np.median(ann_vol_log), color='tab:orange', linewidth=2, linestyle='--', label=f'Median: {np.median(ann_vol_log):.2f}')\n",
    "axes[iax].set_xlabel(\"Annualized Volatility (log returns)\")\n",
    "axes[iax].set_ylabel(\"Counts\")\n",
    "axes[iax].set_xlim(0)\n",
    "axes[iax].legend()\n",
    "\n",
    "iax = 3\n",
    "axes[iax].hist(ann_vol_arith, bins=50)\n",
    "axes[iax].axvline(np.median(ann_vol_arith), color='tab:orange', linewidth=2, linestyle='--', label=f'Median: {np.median(ann_vol_arith):.2f}')\n",
    "axes[iax].set_xlabel(\"Annualized Volatility (arithmetic returns)\")\n",
    "axes[iax].set_ylabel(\"Counts\")\n",
    "axes[iax].set_xlim(0)\n",
    "axes[iax].legend()\n",
    "\n",
    "idx = 4\n",
    "axes[idx].hist(ann_mean_log, bins=50)\n",
    "axes[idx].axvline(np.median(ann_mean_log), color='tab:orange', linewidth=2, linestyle='--', label=f'Median: {np.median(ann_mean_log):.2f}')\n",
    "axes[idx].set_xlabel(\"Annualized Mean (log returns)\")\n",
    "axes[idx].set_ylabel(\"Counts\")\n",
    "axes[idx].set_xlim(0)\n",
    "axes[idx].legend()\n",
    "\n",
    "iax = 5\n",
    "axes[iax].hist(ann_mean_arith, bins=50)\n",
    "axes[iax].axvline(np.median(ann_mean_arith), color='tab:orange', linewidth=2, linestyle='--', label=f'Median: {np.median(ann_mean_arith):.2f}')\n",
    "axes[iax].set_xlabel(\"Annualized Mean (arithmetic returns)\")\n",
    "axes[iax].set_ylabel(\"Counts\")\n",
    "axes[iax].set_xlim(0)\n",
    "axes[iax].legend()\n",
    "\n",
    "# Maximum price range distribution\n",
    "iax = 6\n",
    "max_delta_pct = open_data.max(axis=0) / open_data.min(axis=0)\n",
    "median_delta = max_delta_pct.median()\n",
    "highest_delta = max_delta_pct.idxmax()\n",
    "smallest_delta = max_delta_pct.idxmin()\n",
    "axes[iax].hist(max_delta_pct, bins=100)\n",
    "axes[iax].axvline(median_delta, color='tab:orange', linewidth=2, linestyle='--', label=f'Median: {median_delta:.0%}')\n",
    "axes[iax].plot([], [], label=f\"Largest $\\\\Delta$: {highest_delta} = {max_delta_pct[highest_delta]:.0%}\", color='tab:red')\n",
    "axes[iax].plot([], [], label=f\"Smallest $\\\\Delta$: {smallest_delta} = {max_delta_pct[smallest_delta]:.0%}\", color='tab:green')\n",
    "axes[iax].legend()\n",
    "axes[iax].set_xlim(1)\n",
    "axes[iax].set_ylabel(\"Counts\")\n",
    "axes[iax].set_xlabel(r\"$\\text{Price}_{\\text{max}}~/~\\text{Price}_{\\text{min}}$\")\n",
    "\n",
    "# Total Return Distribution\n",
    "iax = 7\n",
    "median_ret = tot_ret.median()\n",
    "axes[iax].hist(tot_ret, bins=50)\n",
    "axes[iax].set_xlabel('Total Return')\n",
    "axes[iax].set_ylabel('Counts')\n",
    "axes[iax].axvline(0, color='black', linewidth=0.5)\n",
    "axes[iax].axvline(median_ret, color='tab:orange', linewidth=2, linestyle='--', label=f'Median: {median_ret:.2%}')\n",
    "axes[iax].legend()\n",
    "\n",
    "# Sorted return contribution\n",
    "iax = 8\n",
    "gain_to_loss_index = contrib_sorted[contrib_sorted['contribution'] > 0].index[-1]\n",
    "gain_mass = contrib_sorted.loc[:gain_to_loss_index, 'contribution'].sum()\n",
    "loss_mass = contrib_sorted.loc[gain_to_loss_index:, 'contribution'].sum()\n",
    "axes[iax].fill_between(range(0, gain_to_loss_index+1), contrib_sorted.loc[:gain_to_loss_index, 'contribution'].values, color='tab:green')\n",
    "axes[iax].fill_between(range(gain_to_loss_index, len(contrib_sorted)), contrib_sorted.loc[gain_to_loss_index:, 'contribution'].values, color='tab:red')\n",
    "axes[iax].axvline(gain_to_loss_index, color='black', linewidth=1, linestyle='--')\n",
    "axes[iax].axhline(0, color='black', linewidth=0.5)\n",
    "axes[iax].text(gain_to_loss_index-20, axes[iax].get_ylim()[1]*0.9, f'+{gain_mass:.0%} gain mass', color='tab:green', ha='right', va='center')\n",
    "axes[iax].text(gain_to_loss_index+20, axes[iax].get_ylim()[1]*0.9, f'{loss_mass:.0%} loss mass', color='tab:red', ha='left', va='center')\n",
    "axes[iax].axhline(0, color='black', linewidth=0.5)\n",
    "axes[iax].set_xlabel('Ticker Index')\n",
    "axes[iax].set_ylabel('Sorted Return Contribution')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print paragraph of summary\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "console = Console()\n",
    "\n",
    "md = Markdown(f\"\"\"\n",
    "The S&P 500 index has a median annualized volatility of {np.median(ann_vol_arith):.2%} and a median price range (Price_max / Price_min) of {median_delta:.0%}. The S&P 500 index has a median total return of {median_ret:.2%}. An attempt to compute the contribution of each ticker to the index return is currently misleading since the latest market cap data is used (baking in past returns again). With the current procedure, the gain mass is {gain_mass:.0%} and the loss mass is {loss_mass:.0%}.\"\"\")\n",
    "console.print(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
